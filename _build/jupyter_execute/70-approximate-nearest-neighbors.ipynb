{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Nearest Neighbors\n",
    "\n",
    "In the realm of big data, traditional methods like k-NN (k-nearest neighbors) falter due to the sheer volume of information. The solution? \n",
    "\n",
    "Approximate Nearest Neighbors (ANN) algorithms, which aim for close-enough results most of the time, offering a balance between precision and performance.\n",
    "\n",
    " * {ref}`ANNOY` (Approximate Nearest Neighbors Oh Yeah), utilized by Spotify for music recommendations.\n",
    " * {ref}`FAISS`\n",
    "\n",
    "(ANNOY)=\n",
    "## ANNOY\n",
    "\n",
    "[GitHub Repository](https://github.com/spotify/annoy)\n",
    "\n",
    "### Understanding ANNOY\n",
    "\n",
    "ANNOY is designed to efficiently search through large datasets for items that are similar but not necessarily the closest match. It's especially useful when processing time and storage are key considerations.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Distance Metrics Supported**: Euclidean, Manhattan, Cosine, Hamming, and Dot Product.\n",
    "    - **Hamming Distance**: Efficiently handles binary data by operating on 64-bit integers.\n",
    "    - **Dot Product Distance**: Transforms vectors to a cosine space for better query performance, based on research by Microsoft Research.\n",
    "- **Optimized for Lower Dimensions**: Best under 100 dimensions but effective up to 1,000.\n",
    "- **Efficiency**: Minimal memory usage, supports memory sharing across processes.\n",
    "- **Flexibility**: Separate index creation and lookup, with fixed indexing post-creation.\n",
    "- **Scalability**: Can build indexes on disk for datasets too large for memory.\n",
    "\n",
    "\n",
    "\n",
    "### Configuration Parameters\n",
    "\n",
    "- **`n_trees`**: Influences build time and index size. Higher values improve accuracy but increase the index size.\n",
    "- **`search_k`**: Adjusts search performance. Higher values offer more accurate results but are slower. Defaults to `n * n_trees` if unspecified.\n",
    "\n",
    "\n",
    "By adjusting parameters like `n_trees` and `search_k`, and choosing the appropriate distance metric, ANNOY can be finely tuned to balance between accuracy and efficiency, making it a powerful tool for handling large-scale datasets.\n",
    "\n",
    "\n",
    "**Trade-offs**: You can opt for slower searches to reduce load times, memory usage, and disk IO. The index can be loaded in memory upfront or read from disk on-demand, depending on your system's resources and needs.\n",
    "\n",
    "### How ANNOY Works\n",
    "\n",
    "1. ANNOY uses random projections and tree structures to navigate the search space. \n",
    "2. It selects a random hyperplane at each node, dividing the space into two. \n",
    "3. This process repeats, creating a \"forest\" of trees, with the number of trees (`k`) tailored to your precision and performance requirements.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.471435</td>\n",
       "      <td>-1.190976</td>\n",
       "      <td>1.432707</td>\n",
       "      <td>-0.312652</td>\n",
       "      <td>-0.720589</td>\n",
       "      <td>0.887163</td>\n",
       "      <td>0.859588</td>\n",
       "      <td>-0.636524</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>-2.242685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079842</td>\n",
       "      <td>-0.399965</td>\n",
       "      <td>-1.027851</td>\n",
       "      <td>-0.584718</td>\n",
       "      <td>0.816594</td>\n",
       "      <td>-0.081947</td>\n",
       "      <td>-0.344766</td>\n",
       "      <td>0.528288</td>\n",
       "      <td>-1.068989</td>\n",
       "      <td>-0.511881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291205</td>\n",
       "      <td>0.566534</td>\n",
       "      <td>0.503592</td>\n",
       "      <td>0.285296</td>\n",
       "      <td>0.484288</td>\n",
       "      <td>1.363482</td>\n",
       "      <td>-0.781105</td>\n",
       "      <td>-0.468018</td>\n",
       "      <td>1.224574</td>\n",
       "      <td>-1.281108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209395</td>\n",
       "      <td>-0.592886</td>\n",
       "      <td>-1.473116</td>\n",
       "      <td>-0.896581</td>\n",
       "      <td>1.104352</td>\n",
       "      <td>-0.431550</td>\n",
       "      <td>-0.161137</td>\n",
       "      <td>0.889157</td>\n",
       "      <td>0.288377</td>\n",
       "      <td>-1.051539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.319561</td>\n",
       "      <td>-0.619993</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>-0.571455</td>\n",
       "      <td>1.057633</td>\n",
       "      <td>-0.791489</td>\n",
       "      <td>-0.524627</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>1.910759</td>\n",
       "      <td>0.787965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386254</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>-0.683790</td>\n",
       "      <td>1.057203</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>1.343182</td>\n",
       "      <td>-0.050540</td>\n",
       "      <td>-0.364010</td>\n",
       "      <td>-1.553342</td>\n",
       "      <td>-0.319298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.711112</td>\n",
       "      <td>-0.217545</td>\n",
       "      <td>2.637791</td>\n",
       "      <td>-1.742138</td>\n",
       "      <td>-0.094435</td>\n",
       "      <td>1.431184</td>\n",
       "      <td>0.592758</td>\n",
       "      <td>0.170297</td>\n",
       "      <td>-1.751706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393892</td>\n",
       "      <td>-0.950026</td>\n",
       "      <td>0.332507</td>\n",
       "      <td>0.528944</td>\n",
       "      <td>-1.120521</td>\n",
       "      <td>0.048264</td>\n",
       "      <td>0.061988</td>\n",
       "      <td>-1.027516</td>\n",
       "      <td>-0.238335</td>\n",
       "      <td>1.932178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.226632</td>\n",
       "      <td>-0.923831</td>\n",
       "      <td>0.355839</td>\n",
       "      <td>-1.270063</td>\n",
       "      <td>-0.195472</td>\n",
       "      <td>-0.463419</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>1.388647</td>\n",
       "      <td>1.087714</td>\n",
       "      <td>0.438801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725714</td>\n",
       "      <td>0.916976</td>\n",
       "      <td>-0.563890</td>\n",
       "      <td>-1.522180</td>\n",
       "      <td>-0.014279</td>\n",
       "      <td>-0.246721</td>\n",
       "      <td>-0.165329</td>\n",
       "      <td>0.119114</td>\n",
       "      <td>-2.074980</td>\n",
       "      <td>-1.002755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.471435 -1.190976  1.432707 -0.312652 -0.720589  0.887163  0.859588   \n",
       "1  0.291205  0.566534  0.503592  0.285296  0.484288  1.363482 -0.781105   \n",
       "2 -0.319561 -0.619993  0.156998 -0.571455  1.057633 -0.791489 -0.524627   \n",
       "3  0.527046  0.711112 -0.217545  2.637791 -1.742138 -0.094435  1.431184   \n",
       "4 -0.226632 -0.923831  0.355839 -1.270063 -0.195472 -0.463419  0.989415   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.636524  0.015696 -2.242685  ...  0.079842 -0.399965 -1.027851 -0.584718   \n",
       "1 -0.468018  1.224574 -1.281108  ...  0.209395 -0.592886 -1.473116 -0.896581   \n",
       "2  0.071878  1.910759  0.787965  ...  0.386254  0.822775 -0.683790  1.057203   \n",
       "3  0.592758  0.170297 -1.751706  ...  0.393892 -0.950026  0.332507  0.528944   \n",
       "4  1.388647  1.087714  0.438801  ...  0.725714  0.916976 -0.563890 -1.522180   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.816594 -0.081947 -0.344766  0.528288 -1.068989 -0.511881  \n",
       "1  1.104352 -0.431550 -0.161137  0.889157  0.288377 -1.051539  \n",
       "2  0.031880  1.343182 -0.050540 -0.364010 -1.553342 -0.319298  \n",
       "3 -1.120521  0.048264  0.061988 -1.027516 -0.238335  1.932178  \n",
       "4 -0.014279 -0.246721 -0.165329  0.119114 -2.074980 -1.002755  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a random dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "d = 100 # number of dimensions\n",
    "np.random.seed(1234)\n",
    "# 10000 rows and 1000 columns \n",
    "data = np.random.randn(10000, d)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "\n",
    "print(d)  # Length of item vector that will be indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Annoy index\n",
    "t = AnnoyIndex(d, 'angular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Annoy index t is created for 40-dimensional vectors, using the 'angular' distance metric. The angular distance is useful for measuring similarity based on the angle between vectors (often used in text and other types of normalized data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add items to the index\n",
    "for i, row in df.iterrows():\n",
    "    t.add_item(i, row.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.build(10) # 10 trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build method constructs the index using 10 trees. More trees can give more accurate results, but also take more memory and make querying slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.save(\"my_index.ann\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is saved to disk with the filename 'test.ann'. This allows the index to be reloaded later without needing to rebuild it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Index\n",
    "u = AnnoyIndex(d, 'angular')\n",
    "u.load('my_index.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new Annoy index u is created and loaded from the saved file 'my_index.ann'. Loading is typically very fast because it uses memory mapping (mmap), which maps the file directly into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9505, 1842, 9822, 8443, 4612, 9341, 7156, 8157, 8829]\n"
     ]
    }
   ],
   "source": [
    "print(u.get_nns_by_item(0, 10)) # will find the 10 nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This retrieves the 10 nearest neighbors to the item with ID 0 in the index. This is useful for finding items similar to a given item in terms of their vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.741819  1.646627  0.452115  0.882599 -0.661915  0.979095  0.051259   \n",
      "1  0.513265 -0.560029 -1.875828 -0.616818  0.472312 -0.518897  1.403291   \n",
      "2  1.994143 -1.962042  0.310775  1.101320  0.563290  2.175136  0.151669   \n",
      "3 -1.665064 -0.206307 -0.053277  0.881134 -1.761581  0.577637  1.185733   \n",
      "4  0.301827 -0.588839  0.346635  2.454211 -1.641289 -1.892444  0.587601   \n",
      "\n",
      "         7         8         9   ...        90        91        92        93  \\\n",
      "0  0.661035 -0.204227  0.243189  ... -0.191396  0.611696  1.130720 -0.185962   \n",
      "1  0.349392 -0.265442 -0.108946  ...  1.107599  1.971189 -0.482424 -0.919173   \n",
      "2  0.640860  1.065391 -1.004647  ...  0.618361  0.430687 -0.473926 -0.296155   \n",
      "3 -1.375332 -0.368126 -0.862266  ...  0.372291  0.863036 -1.472766  0.198946   \n",
      "4 -0.401334 -0.925195  0.176657  ...  2.160231  0.265586 -0.030451 -0.063437   \n",
      "\n",
      "         94        95        96        97        98        99  \n",
      "0  1.013035 -0.848390 -1.324425  1.041549  0.030705 -0.270555  \n",
      "1 -1.839877  1.544191  0.437576  1.829458 -0.376125  1.337848  \n",
      "2  1.059534 -1.060604  0.562583 -0.769010  1.927553  0.785875  \n",
      "3  0.154797  0.732177  0.516928  1.394767 -0.031738  0.995752  \n",
      "4  0.187774 -0.178658  1.659626  0.317580  0.846268  0.046817  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame(np.random.randn(5, d))\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5983, 5215, 956, 6273, 915]\n",
      "[968, 4406, 810, 8943, 8149]\n",
      "[8343, 5295, 3473, 9330, 2748]\n",
      "[396, 8740, 6628, 6450, 7079]\n",
      "[2489, 5919, 5699, 8600, 8774]\n"
     ]
    }
   ],
   "source": [
    "# Number of nearest neighbors to find\n",
    "num_neighbors = 5\n",
    "\n",
    "# Iterate over each new vector in new_df and find its nearest neighbors\n",
    "for index, row in new_df.iterrows():\n",
    "    vector = row.tolist()\n",
    "    # print(vector)\n",
    "    neighbors = u.get_nns_by_vector(vector, num_neighbors, include_distances=False)\n",
    "    print(neighbors)\n",
    "    # print(f\"Neighbors for new observation {index}: {neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(FAISS)=\n",
    "## FAISS\n",
    "\n",
    "### Introduction\n",
    "Developed by Facebook AI, Faiss represents a groundbreaking approach to similarity search, particularly for multimedia documents. \n",
    "Traditional search engines and database systems struggle with the complexity and scale involved in finding similar high-dimensional vectors, which is crucial for processing and understanding multimedia content. \n",
    "Faiss introduces a solution that is not only faster but also more efficient than any existing technology, boasting an 8.5x speed improvement over the state-of-the-art and establishing new benchmarks in the process.\n",
    "\n",
    "Challengages: \n",
    " * Similarity search involves identifying multimedia documents that resemble each other within huge datasets, which traditional databases, designed for structured, symbolic information, fail to handle effectively. \n",
    " * AI-driven tools like word embeddings and CNN descriptors have made high-dimensional vectors a powerful means for representing multimedia content. However, efficiently querying these vectors for similarity remains a significant challenge, given the sheer volume of data and the computational complexity involved.\n",
    "\n",
    "### Key Features\n",
    "Faiss addresses these challenges head-on by providing an efficient and scalable library tailored for similarity search across billion-scale datasets. It offers several advantages:\n",
    "\n",
    "1. **Speed and Efficiency**: Faiss is optimized to deliver unparalleled search speeds, making it possible to process queries against billions of vectors in a fraction of the time previously required.\n",
    "2. **Memory Optimization**: The library is designed to be light on memory usage, facilitating faster access and processing of large datasets without compromising performance.\n",
    "3. **GPU Acceleration**: With its state-of-the-art GPU implementation, Faiss leverages the power of modern hardware to further enhance search speeds and efficiency.\n",
    "\n",
    "### Software Innovation and Applications\n",
    "Beyond its core functionality, Faiss represents a significant advancement in software engineering for AI applications. It offers:\n",
    "\n",
    " * **Flexibility**: With various similarity search methods, Faiss caters to a wide range of use cases and datasets, providing users with the tools to tailor their search operations according to specific needs.\n",
    " * **Scalability**: Designed to handle databases of billions of vectors, Faiss breaks new ground in scalability, enabling applications that were previously unimaginable due to computational constraints.\n",
    "\n",
    "Specifically, \n",
    "\n",
    "CPU Optimizations:\n",
    " * Multi-threading is utilized to leverage multiple cores for parallel searches across multiple GPUs.\n",
    " * BLAS Libraries are essential for exact distance computations, enabling efficient brute-force implementations via matrix multiplication.\n",
    " * SIMD Vectorization and Popcount techniques accelerate distance computations for individual vectors.\n",
    "\n",
    "GPU Enhancements:\n",
    " * K-Selection Algorithm: A significant advancement in GPU implementations is the development of a highly efficient k-selection algorithm for finding the k-minimum or maximum elements, crucial for similarity searches. This algorithm operates close to peak GPU memory bandwidth efficiency and is designed to work in a single pass, keeping all intermediate states in registers, which allows for integration with other kernels for faster search operations.\n",
    " * Efficient Tiling and Kernel Implementation: The library focuses on effective tiling strategies and kernel functions for approximate search, optimizing performance.\n",
    " * Multi-GPU Support: Faiss allows for data sharding or replication across multiple GPUs, not limiting operations to the memory capacity of a single GPU.\n",
    " * Half-Precision Floating-Point Support: It includes float16 support for both computation and storage, which enhances speed with minimal accuracy loss on supported GPU architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of Nearest Neighbors:\n",
      "[[   0 2240 2975 9327]\n",
      " [   1 8826 4435 1533]\n",
      " [   2 4493 6811 9874]\n",
      " [   3 3371 4861 2566]\n",
      " [   4 9884 4025 3933]]\n",
      "Distances to Nearest Neighbors:\n",
      "[[0.        1.1695111 1.2628028 1.2849629]\n",
      " [0.        1.3047677 1.347751  1.3648174]\n",
      " [0.        1.2633741 1.2682862 1.2734882]\n",
      " [0.        1.2850516 1.3241501 1.3330061]\n",
      " [0.        1.2195594 1.2292215 1.2797881]]\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to numpy array\n",
    "xb = df.to_numpy(dtype='float32')  # FAISS needs float32 data\n",
    "\n",
    "# Normalize the vectors (optional)\n",
    "norm = np.linalg.norm(xb, axis=1, keepdims=True)\n",
    "xb = xb / norm  # Avoid division by zero issues in case of zero vectors\n",
    "\n",
    "# Create a FAISS index - using L2 distance for simplicity\n",
    "index = faiss.IndexFlatL2(d)  # d is the dimensionality of the vectors\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(xb)\n",
    "\n",
    "# Perform a search\n",
    "k = 4  # Number of nearest neighbors to find\n",
    "xq = xb[:5]  # Query the first 5 vectors from the dataset itself as an example\n",
    "D, I = index.search(xq, k)  # D is the distance matrix, I is the index matrix\n",
    "\n",
    "# Display the results\n",
    "print(\"Indices of Nearest Neighbors:\")\n",
    "print(I)\n",
    "print(\"Distances to Nearest Neighbors:\")\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also perform the search process for a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of Nearest Neighbors:\n",
      "[[7913 3935 2320 2171]\n",
      " [1101  968 4631 9352]\n",
      " [5147 8802 2311  105]\n",
      " [ 449 5731 8035 9890]\n",
      " [8359  699 1995 5096]]\n",
      "Distances to Nearest Neighbors:\n",
      "[[1.1784326 1.1884484 1.3003789 1.3152766]\n",
      " [1.219982  1.312232  1.312483  1.3187146]\n",
      " [1.2540469 1.2751344 1.2969229 1.3039747]\n",
      " [1.290485  1.320958  1.3216754 1.3329273]\n",
      " [1.305373  1.3320141 1.3333966 1.3549589]]\n"
     ]
    }
   ],
   "source": [
    "# Convert new DataFrame to numpy array\n",
    "xq = new_df.to_numpy(dtype='float32')\n",
    "\n",
    "# Normalize the vectors (only if the original data was normalized)\n",
    "norm = np.linalg.norm(xq, axis=1, keepdims=True)\n",
    "xq = xq / norm  # Avoid division by zero issues in case of zero vectors\n",
    "\n",
    "# Perform a search\n",
    "k = 4  # Number of nearest neighbors to find\n",
    "D, I = index.search(xq, k)  # D is the distance matrix, I is the index matrix\n",
    "\n",
    "# Display the results\n",
    "print(\"Indices of Nearest Neighbors:\")\n",
    "print(I)\n",
    "print(\"Distances to Nearest Neighbors:\")\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}