@inproceedings{holdgraf_evidence_2014,
	title        = {Evidence for {Predictive} {Coding} in {Human} {Auditory} {Cortex}},
	author       = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Knight, Robert T.},
	year         = 2014,
	booktitle    = {International {Conference} on {Cognitive} {Neuroscience}},
	publisher    = {Frontiers in Neuroscience},
	address      = {Brisbane, Australia, Australia}
}
@article{lessmann2015benchmarking,
	title        = {Benchmarking state-of-the-art classification algorithms for credit scoring: An update of research},
	author       = {Lessmann, Stefan and Baesens, Bart and Seow, Hsin-Vonn and Thomas, Lyn C},
	year         = 2015,
	journal      = {European Journal of Operational Research},
	publisher    = {Elsevier},
	volume       = 247,
	number       = 1,
	pages        = {124--136}
}
@article{gunnarsson2021deep,
	title        = {Deep learning for credit scoring: Do or don’t?},
	author       = {Gunnarsson, Bj{\"o}rn Rafn and Vanden Broucke, Seppe and Baesens, Bart and {\'O}skarsd{\'o}ttir, Mar{\'\i}a and Lemahieu, Wilfried},
	year         = 2021,
	journal      = {European Journal of Operational Research},
	publisher    = {Elsevier},
	volume       = 295,
	number       = 1,
	pages        = {292--305}
}
@article{abdou2011credit,
	title        = {Credit scoring, statistical techniques and evaluation criteria: a review of the literature},
	author       = {Abdou, Hussein A and Pointon, John},
	year         = 2011,
	journal      = {Intelligent systems in accounting, finance and management},
	publisher    = {Wiley Online Library},
	volume       = 18,
	number       = {2-3},
	pages        = {59--88}
}
@article{hlongwane2024enhancing,
	title        = {Enhancing credit scoring accuracy with a comprehensive evaluation of alternative data},
	author       = {Hlongwane, Rivalani and Ramaboa, Kutlwano KKM and Mongwe, Wilson},
	year         = 2024,
	journal      = {Plos one},
	publisher    = {Public Library of Science San Francisco, CA USA},
	volume       = 19,
	number       = 5,
	pages        = {e0303566}
}
@article{nalic2020new,
	title        = {New hybrid data mining model for credit scoring based on feature selection algorithm and ensemble classifiers},
	author       = {Nali{\'c}, Jasmina and Martinovi{\'c}, Goran and {\v{Z}}agar, Drago},
	year         = 2020,
	journal      = {Advanced Engineering Informatics},
	publisher    = {Elsevier},
	volume       = 45,
	pages        = 101130
}
@article{tripathi2018hybrid,
	title        = {Hybrid credit scoring model using neighborhood rough set and multi-layer ensemble classification},
	author       = {Tripathi, Diwakar and Edla, Damodar Reddy and Cheruku, Ramalingaswamy},
	year         = 2018,
	journal      = {Journal of Intelligent \& Fuzzy Systems},
	publisher    = {IOS Press},
	volume       = 34,
	number       = 3,
	pages        = {1543--1549}
}
@article{trivedi2020study,
	title        = {A study on credit scoring modeling with different feature selection and machine learning approaches},
	author       = {Trivedi, Shrawan Kumar},
	year         = 2020,
	journal      = {Technology in Society},
	publisher    = {Elsevier},
	volume       = 63,
	pages        = 101413
}
@article{zhang2021hoba,
	title        = {HOBA: A novel feature engineering methodology for credit card fraud detection with a deep learning architecture},
	author       = {Zhang, Xinwei and Han, Yaoci and Xu, Wei and Wang, Qili},
	year         = 2021,
	journal      = {Information Sciences},
	publisher    = {Elsevier},
	volume       = 557,
	pages        = {302--316}
}
@article{agarwal2018predicting,
	title        = {Predicting financial trouble using call data—On social capital, phone logs, and financial trouble},
	author       = {Agarwal, Rishav Raj and Lin, Chia-Ching and Chen, Kuan-Ta and Singh, Vivek Kumar},
	year         = 2018,
	journal      = {PloS one},
	publisher    = {Public Library of Science San Francisco, CA USA},
	volume       = 13,
	number       = 2,
	pages        = {e0191863}
}
@inproceedings{pedro2015mobiscore,
	title        = {MobiScore: towards universal credit scoring from mobile phone data},
	author       = {Pedro, Jose San and Proserpio, Davide and Oliver, Nuria},
	year         = 2015,
	booktitle    = {International conference on user modeling, adaptation, and personalization},
	pages        = {195--207},
	organization = {Springer}
}
@incollection{de2011towards,
	title        = {Towards a psychographic user model from mobile phone usage},
	author       = {de Oliveira, Rodrigo and Karatzoglou, Alexandros and Concejero Cerezo, Pedro and Armenta Lopez de Vicu{\~n}a, Ana and Oliver, Nuria},
	year         = 2011,
	booktitle    = {CHI'11 Extended Abstracts on Human Factors in Computing Systems},
	pages        = {2191--2196}
}
@inproceedings{ots2020mobile,
	title        = {Mobile phone usage data for credit scoring},
	author       = {Ots, Henri and Liiv, Innar and Tur, Diana},
	year         = 2020,
	booktitle    = {Databases and Information Systems: 14th International Baltic Conference, DB\&IS 2020, Tallinn, Estonia, June 16--19, 2020, Proceedings 14},
	pages        = {82--95},
	organization = {Springer}
}
@article{oskarsdottir2019value,
	title        = {The value of big data for credit scoring: Enhancing financial inclusion using mobile phone data and social network analytics},
	author       = {{\'O}skarsd{\'o}ttir, Mar{\'\i}a and Bravo, Cristi{\'a}n and Sarraute, Carlos and Vanthienen, Jan and Baesens, Bart},
	year         = 2019,
	journal      = {Applied Soft Computing},
	publisher    = {Elsevier},
	volume       = 74,
	pages        = {26--39}
}
@article{de2019does,
	title        = {What does your Facebook profile reveal about your creditworthiness? Using alternative data for microfinance},
	author       = {De Cnudde, Sofie and Moeyersoms, Julie and Stankova, Marija and Tobback, Ellen and Javaly, Vinayak and Martens, David},
	year         = 2019,
	journal      = {Journal of the Operational Research Society},
	publisher    = {Taylor \& Francis},
	volume       = 70,
	number       = 3,
	pages        = {353--363}
}
@article{ge2017predicting,
	title        = {Predicting and deterring default with social media information in peer-to-peer lending},
	author       = {Ge, Ruyi and Feng, Juan and Gu, Bin and Zhang, Pengzhu},
	year         = 2017,
	journal      = {Journal of Management Information Systems},
	publisher    = {Taylor \& Francis},
	volume       = 34,
	number       = 2,
	pages        = {401--424}
}
@article{wei2016credit,
	title        = {Credit scoring with social network data},
	author       = {Wei, Yanhao and Yildirim, Pinar and Van den Bulte, Christophe and Dellarocas, Chrysanthos},
	year         = 2016,
	journal      = {Marketing Science},
	publisher    = {INFORMS},
	volume       = 35,
	number       = 2,
	pages        = {234--258}
}
@article{arraiz2017psychometrics,
	title        = {Psychometrics as a tool to improve credit information},
	author       = {Arr{\'a}iz, Irani and Bruhn, Miriam and Stucchi, Rodolfo},
	year         = 2017,
	journal      = {The World Bank Economic Review},
	publisher    = {Oxford University Press},
	volume       = 30,
	number       = {Supplement\_1},
	pages        = {S67--S76}
}
@article{djeundje2021enhancing,
	title        = {Enhancing credit scoring with alternative data},
	author       = {Djeundje, Viani B and Crook, Jonathan and Calabrese, Raffaella and Hamid, Mona},
	year         = 2021,
	journal      = {Expert Systems with Applications},
	publisher    = {Elsevier},
	volume       = 163,
	pages        = 113766
}
@article{roy2023credit,
	title        = {A credit scoring model for SMEs using AHP and TOPSIS},
	author       = {Roy, Pranith K and Shaw, Krishnendu},
	year         = 2023,
	journal      = {International Journal of Finance \& Economics},
	publisher    = {Wiley Online Library},
	volume       = 28,
	number       = 1,
	pages        = {372--391}
}
@article{yap2011using,
	title        = {Using data mining to improve assessment of credit worthiness via credit scoring models},
	author       = {Yap, Bee Wah and Ong, Seng Huat and Husain, Nor Huselina Mohamed},
	year         = 2011,
	journal      = {Expert Systems with Applications},
	publisher    = {Elsevier},
	volume       = 38,
	number       = 10,
	pages        = {13274--13283}
}
@article{chuang2009constructing,
	title        = {Constructing a reassigning credit scoring model},
	author       = {Chuang, Chun-Ling and Lin, Rong-Ho},
	year         = 2009,
	journal      = {Expert Systems with Applications},
	publisher    = {Elsevier},
	volume       = 36,
	number       = 2,
	pages        = {1685--1694}
}
@article{west2000neural,
	title        = {Neural network credit scoring models},
	author       = {West, David},
	year         = 2000,
	journal      = {Computers \& operations research},
	publisher    = {Elsevier},
	volume       = 27,
	number       = {11-12},
	pages        = {1131--1152}
}
@article{https://doi.org/10.1002/jid.3751,
	title        = {A review of machine learning and satellite imagery for poverty prediction: Implications for development research and applications},
	author       = {Hall, Ola and Dompae, Francis and Wahab, Ibrahim and Dzanku, Fred Mawunyo},
	year         = 2023,
	journal      = {Journal of International Development},
	volume       = 35,
	number       = 7,
	pages        = {1753--1768},
	doi          = {https://doi.org/10.1002/jid.3751},
	url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jid.3751},
	keywords     = {deep learning, machine learning, poverty analysis, satellite imagery, welfare},
	eprint       = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jid.3751},
	abstract     = {Abstract The field of artificial intelligence is seeing the increased application of satellite imagery to analyse poverty in its various manifestations. This nascent but rapidly growing intersection of scholarship holds the potential to help us better understand poverty by leveraging big data and recent advances in machine vision. In this study, we statistically analyse the literature in the expanding field of welfare and poverty predictions from the combination of machine learning and satellite imagery. Here, we apply an integrative review method to extract key data on factors related to the predictive power of welfare. We found that the most important factors correlated to the predictive power of welfare are the number of pre-processing steps employed, the number of datasets used, the type of welfare indicator targeted and the choice of AI model. Studies that used stock measure indicators (assets) as targets achieved better performance—17 percentage points higher—in predicting welfare than those that targeted flow measures (income and consumption) ones. Additionally, we found that the combination of machine learning and deep learning significantly increases predictive power—by as much as 15 percentage points—compared to using either alone. Surprisingly, we found that the spatial resolution of the satellite imagery used is important but not critical to the performance as the relationship is positive but not statistically significant. These findings have important implications for future research in this domain and for anyone aspiring to use the methodology.}
}
@article{holdgraf_rapid_2016,
	title        = {Rapid tuning shifts in human auditory cortex enhance speech intelligibility},
	author       = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Rieger, Jochem W. and Crone, Nathan and Lin, Jack J. and Knight, Robert T. and Theunissen, Frédéric E.},
	year         = 2016,
	journal      = {Nature Communications},
	volume       = 7,
	number       = {May},
	pages        = 13654,
	doi          = {10.1038/ncomms13654},
	issn         = {2041-1723},
	url          = {http://www.nature.com/doifinder/10.1038/ncomms13654},
	file         = {Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:C\:\\Users\\chold\\Zotero\\storage\\MDQP3JWE\\Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:application/pdf}
}
@inproceedings{holdgraf_portable_2017,
	title        = {Portable learning environments for hands-on computational instruction using container-and cloud-based technology to teach data science},
	author       = {Holdgraf, Christopher Ramsay and Culich, A. and Rokem, A. and Deniz, F. and Alegro, M. and Ushizima, D.},
	year         = 2017,
	booktitle    = {{ACM} {International} {Conference} {Proceeding} {Series}},
	volume       = {Part F1287},
	doi          = {10.1145/3093338.3093370},
	isbn         = {978-1-4503-5272-7},
	abstract     = {© 2017 ACM. There is an increasing interest in learning outside of the traditional classroom setting. This is especially true for topics covering computational tools and data science, as both are challenging to incorporate in the standard curriculum. These atypical learning environments offer new opportunities for teaching, particularly when it comes to combining conceptual knowledge with hands-on experience/expertise with methods and skills. Advances in cloud computing and containerized environments provide an attractive opportunity to improve the effciency and ease with which students can learn. This manuscript details recent advances towards using commonly-Available cloud computing services and advanced cyberinfrastructure support for improving the learning experience in bootcamp-style events. We cover the benets (and challenges) of using a server hosted remotely instead of relying on student laptops, discuss the technology that was used in order to make this possible, and give suggestions for how others could implement and improve upon this model for pedagogy and reproducibility.},
	keywords     = {Teaching, Bootcamps, Cloud computing, Data science, Docker, Pedagogy}
}
@article{holdgraf_encoding_2017,
	title        = {Encoding and decoding models in cognitive electrophysiology},
	author       = {Holdgraf, Christopher Ramsay and Rieger, J.W. and Micheli, C. and Martin, S. and Knight, R.T. and Theunissen, F.E.},
	year         = 2017,
	journal      = {Frontiers in Systems Neuroscience},
	volume       = 11,
	doi          = {10.3389/fnsys.2017.00061},
	issn         = 16625137,
	abstract     = {© 2017 Holdgraf, Rieger, Micheli, Martin, Knight and Theunissen. Cognitive neuroscience has seen rapid growth in the size and complexity of data recorded from the human brain as well as in the computational tools available to analyze this data. This data explosion has resulted in an increased use of multivariate, model-based methods for asking neuroscience questions, allowing scientists to investigate multiple hypotheses with a single dataset, to use complex, time-varying stimuli, and to study the human brain under more naturalistic conditions. These tools come in the form of “Encoding” models, in which stimulus features are used to model brain activity, and “Decoding” models, in which neural features are used to generated a stimulus output. Here we review the current state of encoding and decoding models in cognitive electrophysiology and provide a practical guide toward conducting experiments and analyses in this emerging field. Our examples focus on using linear models in the study of human language and audition. We show how to calculate auditory receptive fields from natural sounds as well as how to decode neural recordings to predict speech. The paper aims to be a useful tutorial to these approaches, and a practical introduction to using machine learning and applied statistics to build models of neural activity. The data analytic approaches we discuss may also be applied to other sensory modalities, motor systems, and cognitive systems, and we cover some examples in these areas. In addition, a collection of Jupyter notebooks is publicly available as a complement to the material covered in this paper, providing code examples and tutorials for predictive modeling in python. The aimis to provide a practical understanding of predictivemodeling of human brain data and to propose best-practices in conducting these analyses.},
	keywords     = {Decoding models, Encoding models, Electrocorticography (ECoG), Electrophysiology/evoked potentials, Machine learning applied to neuroscience, Natural stimuli, Predictive modeling, Tutorials}
}
@book{ruby,
	title        = {The Ruby Programming Language},
	author       = {Flanagan, David and Matsumoto, Yukihiro},
	year         = 2008,
	publisher    = {O'Reilly Media}
}
@article{wachter2017counterfactual,
	title        = {Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
	author       = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	year         = 2017,
	journal      = {Harv. JL \& Tech.},
	publisher    = {HeinOnline},
	volume       = 31,
	pages        = 841
}
@article{cox1958regression,
  title={The Regression Analysis of Binary Sequences},
  author={Cox, D. R.},
  journal={Journal of the Royal Statistical Society},
  year={1958}
}

@article{hoerl1970ridge,
  title={Ridge Regression: Biased Estimation for Nonorthogonal Problems},
  author={Hoerl, A. E. and Kennard, R. W.},
  journal={Technometrics},
  year={1970}
}

@article{tibshirani1996lasso,
  title={Regression Shrinkage and Selection via the Lasso},
  author={Tibshirani, R.},
  journal={Journal of the Royal Statistical Society},
  year={1996}
}

@article{cortes1995svm,
  title={Support-Vector Networks},
  author={Cortes, C. and Vapnik, V.},
  journal={Machine Learning},
  year={1995}
}

@article{breiman2001random,
  title={Random Forests},
  author={Breiman, L.},
  journal={Machine Learning},
  year={2001}
}

@article{friedman2001gradient,
  title={Greedy Function Approximation: A Gradient Boosting Machine},
  author={Friedman, J. H.},
  journal={The Annals of Statistics},
  year={2001}
}

@article{rosenblatt1958perceptron,
  title={The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain},
  author={Rosenblatt, F.},
 journal={Psychological Review},
  year={1958}
}

@article{lecun1998cnn,
  title={Gradient-Based Learning Applied to Document Recognition},
  author={LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE},
  year={1998}
}

@article{rumelhart1986rnn,
  title={Learning Representations by Back-Propagating Errors},
  author={Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
  journal={Nature},
  year={1986}
}

@article{cover1967knn,
  title={Nearest Neighbor Pattern Classification},
  author={Cover, T. M. and Hart, P. E.},
  journal={IEEE Transactions on Information Theory},
  year={1967}
}

@article{fisher1936lda,
  title={The Use of Multiple Measurements in Taxonomic Problems},
  author={Fisher, R. A.},
  journal={Annals of Eugenics},
  year={1936}
}

@article{goodfellow2014gan,
  title={Generative Adversarial Networks},
  author={Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
  journal={arXiv preprint},
  year={2014}
}

@article{duda1973pattern,
  title={Pattern Classification and Scene Analysis},
  author={Duda, R. O. and Hart, P. E.},
  journal={Wiley},
  year={1973}
}

@article{mclachlan2000finite,
  title={Finite Mixture Models},
  author={McLachlan, G. and Peel, D.},
  journal={Wiley},
  year={2000}
}

@article{rabiner1989tutorial,
  title={A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition},
  author={Rabiner, L. R.},
  journal={Proceedings of the IEEE},
  year={1989}
}

@article{breiman1996bagging,
  title={Bagging Predictors},
  author={Breiman, L.},
  journal={Machine Learning},
  year={1996}
}

@article{freund1997decision,
  title={A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
  author={Freund, Y. and Schapire, R. E.},
  journal={Journal of Computer and System Sciences},
  year={1997}
}

@article{tibshirani1996lasso,
  title={Regression Shrinkage and Selection via the Lasso},
  author={Tibshirani, R.},
  journal={Journal of the Royal Statistical Society},
  year={1996}
}

@article{hoerl1970ridge,
  title={Ridge Regression: Biased Estimation for Nonorthogonal Problems},
  author={Hoerl, A. E., & Kennard, R. W.},
  journal={Technometrics},
  year={1970}
}

@article{friedman2001gradient,
  title={Greedy Function Approximation: A Gradient Boosting Machine},
  author={Friedman, J. H.},
  journal={The Annals of Statistics},
  year={2001}
}

@article{breiman1996bagging,
  title={Bagging Predictors},
  author={Breiman, L.},
  journal={Machine Learning},
  year={1996}
}